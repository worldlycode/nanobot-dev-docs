{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"NanoBot-Dev Documentation \ud83e\udd16","text":"<p>Welcome to the NanoBot-Dev documentation. This site provides comprehensive information about using and extending the NanoBot development pipeline.</p>"},{"location":"#what-is-nanobot","title":"What is NanoBot?","text":"<p>NanoBot is a GenAI powered document processing and retrieval system with vector search capabilities. It allows you to:</p> <ul> <li>Process documents (PDF, DOCX, TXT, Google Sheets etc)</li> <li>Chunk documents into manageable pieces</li> <li>Generate vector embeddings</li> <li>Store the document data and text in a relational database</li> <li>Search documents via a simple chatbot interface</li> </ul> <p></p>"},{"location":"#purpose-of-this-development-codebase","title":"Purpose of this development codebase","text":"<p>We are developing a codebase that creates an intuitive pipeline that can be easily followed, understood and modified by all members involved in the development. The Dev component is a robust pipeline that can empower people and organizations to generate their very own Bot with their own documentation, enabling them to also demonstrate and understand the power and potential of GenAI in their own labs, facilities and research.</p> <p>This project presumes that an out-of-the-box chatbot developed using many online WYSIWYG frameworks is great for concept, but often fails on utility. By introducing and teaching these concepts in a python codebase framework, we open up the power of Generative AI with only a few customizations.  </p> <p>It is our hope by doing so, that we not only create a cohesive codebase with functional code for our respective facilities, but that we are able to bring new members on board to help them employ instances of this codebase at their own locations. This building of code simultaneously builds community and further collaboration \u2014 this is \\(\\mathbf{C}^3\\)</p>"},{"location":"#our-current-selections-for-infrastructure","title":"Our Current Selections for Infrastructure","text":"<p>As of 4/20/2025</p> <p>The current codebase aims to simplify some of the initial setup and modification of the basic steps of an application.  We have some boilerplate code that organized the steps of a RAG (Retrieval Augmented Generation) Generative AI system, and that has consolidated areas of code where one can modify the parameters of each module, simplyfying the use of the codebase.</p>"},{"location":"#python-as-our-language","title":"Python as our Language","text":"<p>Pyuthon is the standard language for most Generative AI applications, and is particullary easy to use. This module require <code>Python 3.12</code> or above.  </p>"},{"location":"#document-parsing-and-chunking","title":"Document parsing and chunking","text":"<p>We are currently using IBM's Docling which can be used to convert most general document formats (and even websites) into a format readable and usable to most Generative AI models.  In particular it is especially good at PDFs, and creates a Docling Document that seperatly identifies and extracts text, tables, pictures, document hierarchy with headers, sections and groups, and understands the content within the context of the page.  </p> <p>To start, we are extracting all the text and table and the provenance information (such as pages number, file name, and heading the information is part of)</p>"},{"location":"#database","title":"Database","text":"<p>We currently are using Neon.tech for our Postgres database.  Postgres is an optimal solution at this early stage as postgres allows, via the pgvector plugin, semantic similarity searches by vector arithmetic.  </p> <p>This choice to use Neon.Tech provides a web based solution, using the power of postgres and takes advantage of Neon's capability for data versioning and branching.</p>"},{"location":"#prompts-with-jinja-templates","title":"Prompts with Jinja Templates","text":"<p>In this structure, we separate out the prompts for each call to the GenAI model so as to extract this from the working code, to make it more transparent, and to be able to easily modify the prompt for testing.</p> <p>The prompts are formatted and delivered to the model using Jinja templates, which also allows us to separate the functionality from the other Python code as well.  </p>"},{"location":"#choice-of-generative-ai-models","title":"Choice of Generative AI Models","text":"<p>At this point we are using OpenAI for all aspects of our GenAI needs.  This includes using <code>4o</code> for the cleaning and formatting of the documents, the embedding of the vectors using , and <code>4o</code> for the chat completion steps.  </p> <p>This choice is currently determined by the quality and output of the model, and the ease of interacting with the API.  </p>"},{"location":"#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Getting Started - Installation and basic setup</li> <li>User Guide - Detailed usage instructions</li> <li>API Reference - Technical reference for developers</li> <li>Examples - Code examples and tutorials</li> </ul>"},{"location":"examples/","title":"Examples","text":"<p>this is where examples will go</p>"},{"location":"api/database/","title":"Database","text":""},{"location":"api/database/#understanding-the-database-transaction-management-code","title":"Understanding the Database Transaction Management Code","text":"<p>This code is in <code>/database/transaction.py</code> but is not yet implemented except in the <code>/tests/</code> directory</p> <p>Let's break down this transaction management code step by step:</p>"},{"location":"api/database/#1-imports-and-setup","title":"1. Imports and Setup","text":"<pre><code>import time\nimport logging\nimport psycopg2\nfrom contextlib import contextmanager\nfrom typing import Optional, Callable, Any\nfrom app.database.db_common import get_connection\nfrom app.config.settings import settings\n\n# Configure logging\nlogger = logging.getLogger(__name__)\n</code></pre> <p>This section: - Imports necessary libraries (time for measuring duration, logging for feedback) - Sets up a logger for this module</p>"},{"location":"api/database/#2-custom-exception-classes","title":"2. Custom Exception Classes","text":"<pre><code>class TransactionError(Exception):\n    \"\"\"Exception raised for transaction-related errors.\"\"\"\n    pass\n\nclass TransactionTimeout(TransactionError):\n    \"\"\"Exception raised when a transaction times out.\"\"\"\n    pass\n</code></pre> <p>These are custom exception classes: - <code>TransactionError</code>: A general error for any transaction problems - <code>TransactionTimeout</code>: A specific error for when transactions take too long (inherits from TransactionError)</p>"},{"location":"api/database/#3-the-main-transaction-context-manager","title":"3. The Main Transaction Context Manager","text":"<pre><code>@contextmanager\ndef transaction(\n    use_neon: Optional[bool] = None,\n    timeout: Optional[float] = None,\n    feedback: bool = True,\n    auto_rollback: bool = True\n):\n</code></pre> <p>This is a context manager (used with <code>with</code> statements) that: - Takes parameters to control behavior:   - <code>use_neon</code>: Whether to use Neon database (overrides settings)   - <code>timeout</code>: Maximum seconds to allow for the transaction   - <code>feedback</code>: Whether to log what's happening   - <code>auto_rollback</code>: Whether to automatically rollback on errors</p>"},{"location":"api/database/#4-transaction-setup","title":"4. Transaction Setup","text":"<pre><code>conn = None\nstart_time = time.time()\ndb_type = \"Neon\" if (use_neon if use_neon is not None else settings.use_neon) else \"local\"\n\ntry:\n    # Get database connection\n    if feedback:\n        logger.info(f\"Starting transaction with {db_type} database\")\n\n    conn = get_connection(use_neon=use_neon)\n</code></pre> <p>This part: - Initializes variables (connection and start time) - Determines which database to use - Logs the start of the transaction (if feedback is enabled) - Gets a database connection</p>"},{"location":"api/database/#5-setting-timeout","title":"5. Setting Timeout","text":"<pre><code># Set timeout if specified\nif timeout is not None and timeout &gt; 0:\n    # Set statement timeout in milliseconds\n    with conn.cursor() as cur:\n        cur.execute(f\"SET statement_timeout = {int(timeout * 1000)}\")\n</code></pre> <p>This sets a PostgreSQL statement timeout if one was specified: - Converts seconds to milliseconds - Tells PostgreSQL to abort any statement that takes longer than this time</p>"},{"location":"api/database/#6-yielding-the-connection","title":"6. Yielding the Connection","text":"<pre><code># Yield connection to the caller\nyield conn\n</code></pre> <p>This is where the context manager pauses and gives control to the code inside the <code>with</code> block. - The connection is passed to your code to use - When your code finishes, execution continues after this line</p>"},{"location":"api/database/#7-committing-the-transaction","title":"7. Committing the Transaction","text":"<pre><code># Check timeout before committing\nif timeout is not None and (time.time() - start_time) &gt; timeout:\n    raise TransactionTimeout(f\"Transaction timed out after {timeout} seconds\")\n\n# Commit the transaction\nconn.commit()\n\nif feedback:\n    duration = time.time() - start_time\n    logger.info(f\"Transaction committed successfully ({duration:.2f}s)\")\n</code></pre> <p>After your code finishes: - It checks if we've exceeded the timeout - If not, it commits the transaction (saves changes to the database) - Logs the successful commit with duration</p>"},{"location":"api/database/#8-handling-connection-errors","title":"8. Handling Connection Errors","text":"<pre><code>except psycopg2.OperationalError as e:\n    if \"statement timeout\" in str(e).lower():\n        if feedback:\n            logger.error(f\"Transaction timed out after {timeout} seconds\")\n        raise TransactionTimeout(f\"Database operation timed out after {timeout} seconds\") from e\n\n    if feedback:\n        logger.error(f\"Database connection error: {e}\")\n\n    if conn and auto_rollback:\n        try:\n            conn.rollback()\n            if feedback:\n                logger.info(\"Transaction rolled back due to connection error\")\n        except Exception as rollback_error:\n            if feedback:\n                logger.error(f\"Failed to rollback transaction: {rollback_error}\")\n\n    raise TransactionError(f\"Database connection error: {e}\") from e\n</code></pre> <p>This handles database connection errors: - Checks if it's a timeout error - Logs the error - Rolls back the transaction if auto_rollback is enabled - Raises a custom exception</p>"},{"location":"api/database/#9-handling-other-exceptions","title":"9. Handling Other Exceptions","text":"<pre><code>except Exception as e:\n    duration = time.time() - start_time\n\n    if feedback:\n        logger.error(f\"Transaction failed after {duration:.2f}s: {e}\")\n\n    if conn and auto_rollback:\n        try:\n            conn.rollback()\n            if feedback:\n                logger.info(\"Transaction rolled back due to error\")\n        except Exception as rollback_error:\n            if feedback:\n                logger.error(f\"Failed to rollback transaction: {rollback_error}\")\n\n    # Re-raise the original exception\n    raise\n</code></pre> <p>This handles any other exceptions: - Logs the error with duration - Rolls back the transaction if auto_rollback is enabled - Re-raises the original exception</p>"},{"location":"api/database/#10-cleanup","title":"10. Cleanup","text":"<pre><code>finally:\n    # Close connection in finally block to ensure it happens\n    if conn:\n        try:\n            conn.close()\n            if feedback:\n                logger.debug(\"Database connection closed\")\n        except Exception as close_error:\n            if feedback:\n                logger.error(f\"Error closing database connection: {close_error}\")\n</code></pre> <p>This cleanup always runs: - Closes the database connection - Logs any errors that occur during closing</p>"},{"location":"api/database/#11-helper-function","title":"11. Helper Function","text":"<pre><code>def execute_with_transaction(\n    func: Callable,\n    *args,\n    use_neon: Optional[bool] = None,\n    timeout: Optional[float] = None,\n    feedback: bool = True,\n    auto_rollback: bool = True,\n    **kwargs\n) -&gt; Any:\n</code></pre> <p>This is a helper function that: - Takes a function and its arguments - Takes the same transaction parameters - Executes the function within a transaction</p> <pre><code>with transaction(\n    use_neon=use_neon,\n    timeout=timeout,\n    feedback=feedback,\n    auto_rollback=auto_rollback\n) as conn:\n    return func(conn, *args, **kwargs)\n</code></pre> <p>It: - Creates a transaction using the context manager - Calls your function with the connection and other arguments - Returns whatever your function returns</p> <p>This helper makes it easier to use transactions without writing the <code>with</code> statement every time.</p>"},{"location":"api/database/#12-usage-example","title":"12 Usage Example","text":"<pre><code>from app.database.transaction import transaction, execute_with_transaction, TransactionError, TransactionTimeout\n\ndef insert_chunk(conn, text, vector, metadata):\n    \"\"\"Insert a chunk into the database.\"\"\"\n    # ... existing implementation ...\n    return chunk_id\n\ndef insert_chunk_with_transaction(text, vector, metadata, use_neon=None, timeout=None):\n    \"\"\"Insert a chunk with transaction management.\"\"\"\n    try:\n        with transaction(use_neon=use_neon, timeout=timeout) as conn:\n            chunk_id = insert_chunk(conn, text, vector, metadata)\n            return chunk_id\n    except TransactionTimeout:\n        print(\"Insert operation timed out\")\n        return None\n    except TransactionError as e:\n        print(f\"Transaction error: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return None\n\n# Alternative using the execute_with_transaction helper\ndef insert_chunk_with_helper(text, vector, metadata, use_neon=None, timeout=None):\n    \"\"\"Insert a chunk using the transaction helper.\"\"\"\n    return execute_with_transaction(\n        insert_chunk,\n        text, vector, metadata,\n        use_neon=use_neon,\n        timeout=timeout\n    )\n</code></pre>"},{"location":"api/services/","title":"Services","text":""},{"location":"assets/templates/blog-template/","title":"[Your Post Title Here]","text":"<p>To copy this template: <pre><code>   cp docs/blog/blog-template.md docs/blog/YYYY-MM-DD-title.md\n</code></pre></p> <p>Date: [Month Day, Year] Author: Worldly Woman</p> <pre><code>\"hello world \ud83c\udf10\"</code></pre> <p>[Write your opening paragraph here. Introduce the topic and why it matters.]</p>"},{"location":"assets/templates/blog-template/#main-section-title","title":"[Main Section Title]","text":""},{"location":"assets/templates/blog-template/#subsection-title","title":"[Subsection Title]","text":"<p>[Main content goes here. You can include links like this: Link Text]</p> <p>You can include images like this:   </p> <p></p> <p>or like this:</p> <p>NOTE: [Use blockquotes for important notes or callouts]</p>"},{"location":"assets/templates/blog-template/#another-subsection","title":"[Another Subsection]","text":"<p>[More content here. Feel free to include code samples:]</p> <pre><code># Example code\ndef hello_world():\n    print(\"Hello, documentation world!\")\n</code></pre>"},{"location":"assets/templates/blog-template/#another-main-section","title":"[Another Main Section]","text":"<p>[Continue with more content as needed]</p>"},{"location":"assets/templates/blog-template/#technical-details","title":"[Technical Details]","text":"<p>[If applicable, include technical details, steps, or instructions]</p> <pre><code># Example command\ncommand --option value\n</code></pre>"},{"location":"assets/templates/blog-template/#detailed-subsection","title":"[Detailed Subsection]","text":"<p>[Add more detailed information if necessary]</p>"},{"location":"assets/templates/blog-template/#important-notes","title":"Important Notes","text":"<ul> <li>[First important point]  </li> <li>[Second important point]  </li> <li>[Third important point]</li> </ul>"},{"location":"assets/templates/blog-template/#closing-thoughts","title":"Closing Thoughts","text":"<p>[Summarize what you've covered and include any final thoughts or future directions]</p> <p>[Optional: Add a fun closing remark or personal touch]</p>"},{"location":"blog/00-index-blog/","title":"Hello World \ud83c\udf10","text":"<p>Welcome to the NanoBot-Dev development blog! </p> <p>Here our team will share updates, insights, and lessons learned while building this project.  </p> <p>Our motto:  Teach it to keep it!</p> <p>Click through the topics in the left sidebar to learn more.  </p>"},{"location":"blog/docling/","title":"Understanding IBM's Docling","text":"<p>Date: April 25, 2025 Author: sam-i-am</p> <pre><code>\"Hello World! \ud83c\udf10\"</code></pre> <p>I am trying to understand the Docling Package, as it is powerful but somewhat complicated under the hood.  The first thing I am beginning to understand is that Docling is the open source itteration of a different tool it released in 2022, called the Deep Search for Discovery Toolkit (DS4SD).  Seep Search was the original solution for PDF documents, and now in 2024 they released docling in the Arxiv paper found at this link.  </p>"},{"location":"blog/docling/#pdf-conversions","title":"PDF Conversions","text":"<p>This is perhaps the main reason to use Docling.  Most python package PDF converters handle the text of a PDF document, and possibly even try to identify tables and images. But the latter in my experience they do not do well.  In addition to that the traditional packages do not capture the context, so they are not able to handle the chunking of \"Sections\" properly.  This means they may not know that a paragraph belongs to a particular section, and perhaps should not be spilt etc.  </p> <p>In any event, these are thisngs that Docling does very well, expecially for something that runs locally and free of charge.  (There are models such as Unstructures, Azure Intellisense, etc that also do a reasonable job but cost money).  Lastly there are methods that are rather state of the art that use MMLM with vision capabilities, to take in each PDF page as an image and then using these models to identify the areas and components of each page.  </p> <p>However, with Docling, IBM has trained two models that run locally (either on CPU or with GPU assist) These models are found on Hugging Face and include:</p> <ul> <li> <p>Layout Model: The layout model will take an image from a page and apply RT-DETR model (RT-DETR is an object detection model that stands for \u201cReal-Time DEtection Transformer.\u201d) in order to find different layout components. It currently detects the labels: Caption, Footnote, Formula, List-item, Page-footer, Page-header, Picture, Section-header, Table, Text, Title. As a reference (from the DocLayNet-paper), this is the performance of standard object detection methods on the DocLayNet dataset compared to human evaluation </p> </li> <li> <p>Table Former: The tableformer model will identify the structure of the table, starting from an image of a table. It uses the predicted table regions of the layout model to identify the tables. Tableformer has SOTA table structure identification.  The Arxiv paper can be found at the following link.  </p> </li> </ul> <p>So we have a lot to figure out here.  But I am convinced this is the way to go for an out-of-the-box methodology.  There is still a learning curve to optimize how to use the chunking module to optimize the vector embeddings.  </p>"},{"location":"blog/logging/","title":"Logging with Python's Standard Library","text":"<p>Date: March 6, 2025  Author: sam-i-am</p> <pre><code>\"Hello World! \ud83c\udf10\"</code></pre> <p>Logging, or tracking what happens as your code executes is pretty important to knowing what happened when things don't go as planned.  I have learned it is like inserting print statements in your code, but these statement can print out to the console (terminal or stdout), to a file, to an external logger (such as Logfire, which I will talk about in another post).  </p> <p>The bottom line is that you can write an awful lot of code in a notebook, or in small modules, and not have to track things.  But when things start getting big, with thousands of lines of code, you really need to be able to log what is going on especially to find bugs etc.  </p> <p>Plus, learning about logging makes you feel like a pro, like you have entered the big-time.  So lets get logging.  </p>"},{"location":"blog/logging/#pythons-logging-module","title":"Python's Logging Module","text":""},{"location":"blog/logging/#installing","title":"Installing","text":"<p>There is nothing to install, the logging module comes standard with Python!  You just need to add the following at the top of your files. <pre><code>import logging\n</code></pre></p>"},{"location":"blog/logging/#setup-logging-config","title":"Setup Logging Config","text":"<p>So I started by following a few tutorials.  The one that helped me the most was from mCoding and called Modern Python Logging.  Click on thumbnail below to be redirected to the video.  </p> <p> </p>"},{"location":"blog/markdown/","title":"\ud83d\udcc4 Markdown Cheatsheet","text":"<p>Date: April 27, 2025   Author: sam-i-am</p> <pre><code>\"Hello World! \ud83c\udf10\"</code></pre> <p>Markdown is a lightweight markup language.  It is a way to annotate plain text to indicate formating (like headings, bold, links etc), without writing full HTML tags.  </p> <p>It results in nicely rendered plain text, is simple, and totally yours to do what you want with.  We are using Mkdocs for our documentation, which creates a site from markdown files.  </p> <p>If you are not familiar with markdown, dont worry!  Below is a simple cheatsheet to help you along.  At the very bottom of this page there is also some links to other resources.  </p>"},{"location":"blog/markdown/#toc","title":"TOC","text":"<ul> <li>Headings</li> <li>Emphasis</li> <li>Lists</li> <li>Links</li> <li>Images</li> <li>Code</li> <li>Blockquote</li> <li>References and Links</li> <li>Horizontal Line</li> </ul>"},{"location":"blog/markdown/#headings","title":"Headings","text":"<pre><code># Heading 1\n## Heading 2\n### Heading 3\n#### Heading 4\n</code></pre>"},{"location":"blog/markdown/#heading-1","title":"Heading 1","text":""},{"location":"blog/markdown/#heading-2","title":"Heading 2","text":""},{"location":"blog/markdown/#heading-3","title":"Heading 3","text":""},{"location":"blog/markdown/#heading-4","title":"Heading 4","text":""},{"location":"blog/markdown/#emphasis","title":"Emphasis","text":"<pre><code>*Italic*  \n**Bold**  \n***Bold and Italic***  \n~~Strikethrough~~\n</code></pre> <p>Italic Bold Bold and Italic ~~Strikethrough~~</p>"},{"location":"blog/markdown/#lists","title":"Lists","text":""},{"location":"blog/markdown/#unordered-list","title":"Unordered List","text":"<pre><code>- Item 1\n- Item 2\n    - Subitem 2a\n    - Subitem 2b\n</code></pre> <ul> <li>Item 1</li> <li>Item 2<ul> <li>Subitem 2a</li> <li>Subitem 2b</li> </ul> </li> </ul>"},{"location":"blog/markdown/#ordered-list","title":"Ordered List","text":"<pre><code>1. First\n2. Second\n3. Third\n</code></pre> <ol> <li>First  </li> <li>Second  </li> <li>Third</li> </ol>"},{"location":"blog/markdown/#links","title":"Links","text":"<pre><code>[Link Text](https://example.com)\n</code></pre> <p>Link Text</p>"},{"location":"blog/markdown/#images","title":"Images","text":"<pre><code>![Alt Text](https://via.placeholder.com/150)\n</code></pre>"},{"location":"blog/markdown/#code","title":"Code","text":""},{"location":"blog/markdown/#inline-code","title":"Inline Code","text":"<pre><code>Here is `inline code`.\n</code></pre> <p>Here is <code>inline code</code>.</p>"},{"location":"blog/markdown/#code-block","title":"Code Block","text":"<p>Use tripple backticks</p> <p>Rendered:</p> <pre><code>def hello():\n    print(\"Hello, world!\")\n</code></pre>"},{"location":"blog/markdown/#blockquote","title":"Blockquote","text":"<pre><code>&gt; This is a blockquote.\n&gt; It can span multiple lines.\n</code></pre> <p>This is a blockquote. It can span multiple lines.</p>"},{"location":"blog/markdown/#horizontal-line","title":"Horizontal Line","text":"<pre><code>---\n</code></pre>"},{"location":"blog/markdown/#references-and-links","title":"References and Links","text":"<ul> <li>\ud83d\udcc4 Markdown Guide - Basic Syntax</li> </ul> <p>Extremely clear and focused just on the main things: headings, bold, italic, lists, links, images, code, blockquotes.</p> <ul> <li>\ud83d\udcc4 Github Markdown-Cheatsheet</li> </ul> <p>A little bit longer but very practical \u2014 shows both the syntax and examples side-by-side.</p> <ul> <li>\ud83d\udcc4 Interactive markdown Tutorial</li> </ul> <p>If you like practice-as-you-learn, this one is great. It walks you through very short lessons where you type Markdown directly into the page.</p>"},{"location":"blog/markdown/#end-of-cheatsheet","title":"\u2705 End of Cheatsheet","text":""},{"location":"blog/mkdocs/","title":"Starting with MkDocs - Love at first use","text":"<p>Date: March 8, 2025   Author: sam-i-am</p> <pre><code>\"Hello World! \ud83c\udf10\"</code></pre> <p>I am sitting here in the St Agnus NYPL Library, where I spent a lot of the past week, writing code.  This has been an incredible journey.  It was only 6 days ago, that I took the time to try and understand how to use Cursor, the VSCode AI developer IDE.  [With Cursor] I have written about 3000 lines of working code, developing the pipeline for Nanobot.  </p> <p>I now need to start with documentation, and I chose to start with MkDocs, and it is rather nice!  </p>"},{"location":"blog/mkdocs/#project-documentation-with-markdown","title":"Project documentation with Markdown","text":""},{"location":"blog/mkdocs/#what-it-does","title":"What it Does","text":"<p>You can find it at MkDocs Pages, and the Github repo is at Github MkDocs</p> <p>The key is that you can do all of the documentation in markdown, which makes understanding and updating easy.  It also gives you a very nice web interface, serving a site and can also deploy to github.io to make the docs part of your repo.  Mindblowing \ud83e\udd2f.</p>"},{"location":"blog/mkdocs/#choosing-your-theme","title":"Choosing Your Theme","text":"<p>The first thing to do is to choose your theme.  There are two built-in themes: * mkdocs * readthedocs</p> <p>There are also many third part themes, which you are advised to use at your own risk.  However, there is another which is highly used and well suported and documented, which has 22k stars and is written by squidfunk:</p> <ul> <li>material</li> </ul> <p>This is what I have decided to use</p>"},{"location":"blog/mkdocs/#choosing-your-plugins","title":"Choosing Your Plugins","text":"<p>Plugins are sometimes third party items.  Be careful.  I tried the mkdocs-video and it did weird stuff and I uninstalled it.  In any event there is a list of Themes and Plugins at the MkDocs Catalog in the README.  </p>"},{"location":"blog/mkdocs/#how-to-install-it","title":"How to install it","text":"<p>There were only 3 pip installs that I had to do.  the <code>mkdocstrings[python]</code> will evidently read your docstrings and create the API docs from them, but I have not used this feature yet so will update when I get there.  </p> <pre><code># Core MkDocs package\npip install mkdocs\n\n# Material theme for MkDocs\npip install mkdocs-material\n\n# MkDocstrings for API documentation from docstrings\npip install mkdocstrings[python]\n</code></pre>"},{"location":"blog/mkdocs/#yml-file-structure","title":"YML File Structure","text":"<p>You will also need a YML file with the configuration <code>mkdocs.yml</code>. My current YAML file looks like:</p> <pre><code>site_name: NanoBot Documentation \ud83e\udd16\nsite_description: Documentation for the NanoBot POC project\nsite_author: Your Name\n\n# Standard docs directory\ndocs_dir: docs\n\ntheme:\n  name: material\n  palette:\n    # Light mode\n    - media: \"(prefers-color-scheme: light)\"\n      scheme: default\n      primary: indigo\n      accent: indigo\n      toggle:\n        icon: material/brightness-7\n        name: Switch to dark mode\n\n    # Dark mode\n    - media: \"(prefers-color-scheme: dark)\"\n      scheme: slate\n      primary: indigo\n      accent: indigo\n      toggle:\n        icon: material/brightness-4\n        name: Switch to light mode\n  features:\n    - navigation.tabs\n    - navigation.sections\n    - navigation.expand\n    - navigation.instant\n    - toc.integrate\n    - search.suggest\n    - search.highlight\n\nmarkdown_extensions:\n  - pymdownx.highlight\n  - pymdownx.superfences\n  - pymdownx.tabbed\n  - pymdownx.tasklist\n  - admonition\n  - toc:\n      permalink: true\n  - pymdownx.emoji:\n      emoji_index: !!python/name:material.extensions.emoji.twemoji\n      emoji_generator: !!python/name:material.extensions.emoji.to_svg\n  - md_in_html\n\nplugins:\n  - search\n  - mkdocstrings:\n      handlers:\n        python:\n          selection:\n            docstring_style: google\n          rendering:\n            show_source: true\n            show_root_heading: true\n\nnav:\n  - Home: index.md\n  - Getting Started: getting-started.md\n  - User Guide:\n    - Overview: user-guide/index.md\n    - Document Processing: user-guide/document-processing.md\n    - Vector Search: user-guide/vector-search.md\n  - API Reference:\n    - Database: api/database.md\n    - Services: api/services.md\n  - Examples: examples.md\n  - Blog: \n    - Overview: blog/index.md\n    - MkDocs: blog/mkdocs-2025-03-08.md\n</code></pre>"},{"location":"blog/mkdocs/#docs-file-structure-holds-all-of-your-markdown-files","title":"docs File structure (Holds all of your Markdown files)","text":"<p>This is my current dir structure.  I place the <code>/docs</code> directory in the root of my nanobot-poc project.  </p> <p>NOTE: The <code>index.md</code> files are necessary</p> <pre><code>docs/\n\u251c\u2500\u2500 api/\n\u2502   \u251c\u2500\u2500 database.md\n\u2502   \u2514\u2500\u2500 services.md\n\u251c\u2500\u2500 blog/\n\u2502   \u251c\u2500\u2500 post-2025-03-08.md\n\u2502   \u2514\u2500\u2500 index.md\n\u251c\u2500\u2500 img/\n\u2502   \u251c\u2500\u2500 nanobot_schema.jpg\n\u251c\u2500\u2500 user-guide/\n\u2502   \u251c\u2500\u2500 document-processing.md\n\u2502   \u251c\u2500\u2500 index.md\n\u2502   \u2514\u2500\u2500 vector-search.md\n\u251c\u2500\u2500 examples.md\n\u251c\u2500\u2500 getting-started.md\n\u2514\u2500\u2500 index.md\n</code></pre>"},{"location":"blog/mkdocs/#how-to-use-it","title":"How to use it","text":"<p>I havent worked with this but more than 1 hour now, but here is what I know:</p> <p>You can serve the pages locally by running the following command from the root <pre><code>mkdocs serve\n</code></pre> This will launch a local server on port 8000 <code>http://127.0.0.1:8000/</code> where you interact with the HTML version of it.  It is evidently a Bootstrap implementation.  </p> <p>NOTE: If you change the YML file you will need to stop the server <code>ctl C</code> and then restart it again by <code>mkdocs serve</code></p> <p>You can add documents to this but to get them seem in the navigation sidebar you need to add them to the YML file.  If you know the file name you can still navigate to it using the URL but you will not see it in the <code>nav</code> sidebar.  </p> <p>You can deploy this to github.  In the case of my own repo of <code>nanobot-poc</code> I would navigate to <code>srobertsphd.github.io/nanobot-poc</code> and this is where it would reside.  There is an order of events though. </p>"},{"location":"blog/mkdocs/#updating-github-repo","title":"Updating GitHub repo","text":"<ol> <li>Update your Markdown Docs</li> <li>Update you <code>mkdocs.yml</code> file to unclude any new docs</li> <li>Navigate to your project directory</li> <li>Push the updated mkdown to the repo <pre><code>git add docs/ mkdocs.yml\ngit commit -m \"updated documentation\"\ngit push\n</code></pre></li> <li>Deploy to GitHub Pages using MkDocs  </li> </ol> <pre><code>  mkdocs gh-deploy\n</code></pre>"},{"location":"blog/mkdocs/#important-notes","title":"Important Notes","text":"<ul> <li>If your repository is private, you'll need a GitHub Pro, Team, or Enterprise account to use GitHub Pages  </li> <li>It may take a few minutes for your site to be available after deployment  </li> <li>You can check the status of your GitHub Pages deployment in your repository settings</li> </ul>"},{"location":"blog/mkdocs/#content-tabs","title":"Content tabs","text":"<p>The indenting here really matters -- needs to be double tabbed</p> <p>this is the markdown for the three tabs below</p> <pre><code>=== \"plain Text\"\n\n    This is some plain text with code\n\n    ```python\n    print(\"hello world\")\n    ```\n\n=== \"Unordered List\"\n\n    * first\n    * second\n    * third\n\n=== \"Ordered List\"\n\n    1. first\n    2. second\n    3. third\n</code></pre> <p>And this renders as the three tabs below</p> plain TextUnordered ListOrdered List <p>This is some plain text with code</p> <pre><code>print(\"hello world\")\n</code></pre> <ul> <li>first</li> <li>second</li> <li>third</li> </ul> <ol> <li>first</li> <li>second</li> <li>third</li> </ol>"},{"location":"blog/mkdocs/#admonishions","title":"Admonishions","text":"<p>Examople of an admonition/callout with a title:</p> <p>Note the types here -- there is also * note * info * success * tip</p> <p>Each have their own icons.  check it out!</p> <p>Title of the Callout</p> <p>this is some text that is indented with 2 tabs.  here is some more text.  also i wanted to say hello world.  this is an amazing place to be these days</p> Title of the COLLAPSIBLE Callout [CLICK on me] <p>this is some text that is indented with 2 tabs.  here is some more text.  also i wanted to say hello world.  this is an amazing place to be these days</p>"},{"location":"blog/mkdocs/#diagram-examples","title":"Diagram Examples","text":""},{"location":"blog/mkdocs/#flowcharts","title":"Flowcharts","text":"<pre><code>graph LR\n  A[Start] --&gt; B{Failure?};\n  B --&gt;|Yes| C[Investigate...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Success!];</code></pre>"},{"location":"blog/mkdocs/#adding-mathjax-for-equation-formatting-and-display","title":"Adding MathJax for Equation formatting and Display","text":"<p>Taken from the documents -- you will need to add a javascripts folder with the following code, and also modify the mkdocs.yml file as below:</p> docs/javascript/mathjax.jsmkdocs.yml <pre><code>window.MathJax = {\n  tex: {\n    inlineMath: [[\"\\\\(\", \"\\\\)\"]],\n    displayMath: [[\"\\\\[\", \"\\\\]\"]],\n    processEscapes: true,\n    processEnvironments: true\n  },\n  options: {\n    ignoreHtmlClass: \".*|\",\n    processHtmlClass: \"arithmatex\"\n  }\n};\n\ndocument$.subscribe(() =&gt; { \n  MathJax.startup.output.clearCache()\n  MathJax.typesetClear()\n  MathJax.texReset()\n  MathJax.typesetPromise()\n})\n</code></pre> <pre><code>markdown_extensions:\n  - pymdownx.arithmatex:\n      generic: true\n\nextra_javascript:\n  - javascripts/mathjax.js\n  - https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js\n</code></pre>"},{"location":"blog/mkdocs/#closing-comments","title":"Closing Comments","text":"<p>Writing code is so much fun. Learning new libraries in minutes is amazing fun<sup>1</sup>. Leaning how to document things and start writing in less than an hour and having it look good and be accessible --&gt; INCREDIBLE good feeling<sup>2</sup>.</p> <p>This is a pretty sweet gig.  </p>"},{"location":"blog/mkdocs/#references","title":"References","text":"<ol> <li> <p>James Willet Dev Full Tutorial To Build And Deploy Your Docs Portal  https://www.youtube.com/watch?v=xlABhbnNrfI\u00a0\u21a9</p> </li> <li> <p>James Willet Dev Getting Started with Material for MkDocs -- https://jameswillett.dev/getting-started-with-material-for-mkdocs/ \u21a9</p> </li> </ol>"},{"location":"blog/packages-and-imports/","title":"Managing Packages and Imports","text":"<p>Date: April 25, 2025 Author: sam-i-am</p> <pre><code>\"Hello World! \ud83c\udf10\"</code></pre>"},{"location":"blog/packages-and-imports/#cleaning-up-your-virrual-environment","title":"Cleaning up your virrual environment","text":"<p>One always wants to would in a development environment.  most often this is done by creating an environment that your codebase depends on using something like <code>venv</code>, which is what we are currently using in our projects.  </p> <p>One of the issues is that every time you do a <code>pip install [package name]</code> it will also install all of the dependencies that that package depends on.  However, in the requirements.txt file it is best practice to only list the top level dependencies, and let pip resolve and install all of the subdependencies.  </p> <p>If you are like me and have a requirements files that includes all of the dependencies including the sub-dependencies, and need to clean all of that up, you can do the following:</p> <ol> <li>Create a backup of your current requirements.txt file <pre><code>cp requirements.txt requirements.txt.bak\n</code></pre></li> <li>Install pipreqs in your activated virtual environment <pre><code>pip install pipreqs\n</code></pre></li> <li>Run pipreqs from the project root <pre><code>pipreqs . --force\n</code></pre></li> </ol>"},{"location":"blog/packages-and-imports/#importing-and-using-local-packages","title":"Importing and using local packages","text":"<p>This is a good reference for importing packages from a good python content creator with the following channel: Tech with Tim:</p> <p></p>"},{"location":"blog/packages-and-imports/#how-to-import-a-module-from-within-the-package","title":"How to import a module from within the package","text":"<p>As an example:  </p> <p>From the chunking.py file in the document_conversion folder, I want to import the Chunks and ChunkMetadata classes from the models.db_schemas module.</p> <pre><code>import sys\nimport os\nparent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\nsys.path.append(parent_dir)\nfrom models.db_schemas import Chunks, ChunkMetadata\n</code></pre> <ol> <li>os.path.abspath(file): This gets the absolute path of the current file (chunking.py).</li> <li>os.path.dirname(): Called twice to move up two directory levels, reaching the root of your project (nanobot-poc).</li> <li>sys.path.append(parent_dir): Adds the parent directory to sys.path, which is the list of directories Python searches for modules. By including the parent directory, Python can now find models.db_schemas because models is a sibling directory to document_conversion.</li> <li>Import Statement: With the parent directory in sys.path, the import from models.db_schemas import Chunks, ChunkMetadata works because Python can now locate the models directory.</li> </ol> <p>This method effectively adjusts the module search path at runtime, allowing you to import modules from sibling directories.</p>"},{"location":"blog/pgadmin/","title":"Configuring pgAdmin for PostgreSQL","text":"<p>Date: April 27, 2025 Author: sam-i-am</p> <pre><code>\"Hello World! \ud83c\udf10\"</code></pre> <p>pgAdmin is an Open Source administration and development platform for PostgreSQL -- Which claims to be the most advanced Open Source database in the world.  </p> <p>I don't know about that claim, but PostgreSQL is pretty great, it does have plugins for embedding vectors and vector indexing.  So I am currently a fan :)</p> <p>This is how I installed pgAdmin on Windows</p> <ol> <li>Downloaded and installed pgAdmin from their website</li> <li>run pgadmin4</li> <li>right click on \"servers\" and click \"register\" -&gt; \"server\"</li> <li>enter the following information:<ul> <li>General:<ul> <li>Name: {name of the instance of the database}</li> </ul> </li> <li>Connection:<ul> <li>Host: {host of the database} -- if local it will be 127.0.0.1</li> <li>Port: {port of the database} -- default is 5432, but this is often already used, so could create a new port number</li> <li>Maintenance database: {name of the database} -- if local it will be postgres</li> <li>Username: {username of the database} -- if local it will be postgres</li> <li>Password: {password of the database} -- if local it will be postgres</li> </ul> </li> <li>Save</li> </ul> </li> </ol> <p>At this point the connect will either be made or if there is an error you should follow the errors to fix the issue.  </p>"},{"location":"blog/scripts-and-modules/","title":"Scripts and modules","text":""},{"location":"blog/scripts-and-modules/#option-1-run-a-module-as-the-main-program","title":"Option 1:  run a module as the main program","text":"<ul> <li>remember tha a file contining python code used by other parts of a package is a \"module\" even if it only has one line of code in it</li> <li>The code must be in the directory tree of the projects and this must be executed from the project root directory</li> <li>this will execute all of the code in that module, and is a good way to execute <code>__main__</code> code</li> </ul> <p>To execute this you want to use the following syntax <pre><code>python -m modulepath.modulename\n</code></pre></p> <ul> <li>the <code>-m</code> means that it is searching for a module</li> <li>we give dots - <code>.</code> notatiion as this is how we define the paths as in an import statement.  </li> <li>there is no extension <code>.py</code> as we are refereing to it by its import path, not its filename</li> </ul>"},{"location":"blog/scripts-and-modules/#option-2-execute-a-standalone-script","title":"Option 2: Execute a standalone script","text":"<p><pre><code>python run_example_directly.py\n</code></pre> In this case the code is not part of the package, and the code resides outside of the package.  </p>"},{"location":"setup/00-index-setup/","title":"Getting Started with NanoBot","text":"<p>This guide will help you set up and start using NanoBot.</p>"},{"location":"setup/00-index-setup/#installation-prerequisites","title":"Installation Prerequisites","text":"<ul> <li>Python 3.10+ (I am using 3.12.x)</li> <li>PostgreSQL with pgvector extension in 1 of the following configurations:<ul> <li>Local Pastgres Installation</li> <li>Neon database URL (neon.tech)</li> </ul> </li> <li>OpenAI API key</li> <li>Logfire token (for logging LLM calls)</li> </ul>"},{"location":"setup/00-index-setup/#installation","title":"Installation","text":"<ol> <li> <p>Clone the repository:    <pre><code>git clone https://github.com/worldlycode/nanobot-dev.git\ncd nanobot-dev\n</code></pre></p> </li> <li> <p>Create a virtual environment:    <pre><code>python -m venv .venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install dependencies: <pre><code>pip install -r requirements.txt\n</code></pre>    Note this make take severl minute as the Docling library installs several ML models from hugging face, and also pytorch packages to run these locally</p> </li> </ol>"},{"location":"setup/00-index-setup/#setup","title":"Setup","text":"<p>See more details in the following setup files</p> <ol> <li> <p>Set up environment variables:  </p> <p>NOTE: This section is under development    Create a <code>.env</code> file with the following variables:    <pre><code>OPENAI_API_KEY=your_openai_api_key\nLOCAL_DB_NAME=nanobot\nLOCAL_DB_USER=postgres\nLOCAL_DB_PASSWORD=your_password\nLOCAL_DB_HOST=localhost\nLOCAL_DB_PORT=5432\nLOGFIRE_TOKEN=your_logfire_token\nNEON_URL=your_neon_db_url\nUSE_NEON=False (defaults to using local db)\n</code></pre></p> </li> <li> <p>Initialize the database:  </p> <p>NOTE: This section is under development    <pre><code>python -m app.database.db_setup\n</code></pre></p> </li> <li> <p>Run the test files:    Run the following command:    <pre><code>pytest tests\n</code></pre></p> </li> </ol>"},{"location":"setup/00-index-setup/#running-the-application","title":"Running the Application","text":"<p>Start the Streamlit web interface from the root directory:</p> <pre><code>streamlit run nanobot.py\n</code></pre> <p>This will open a web browser with the NanoBot interface.</p>"},{"location":"setup/database-table-setup/","title":"Initializing your Database","text":"<ul> <li>Toggle switch in your environment file or in <code>app.config.settings.py</code> to be local or Neon.  </li> <li>runn the code to set up the tables in the chosen location</li> <li>Import sample data</li> <li>Have a script that tests this sample data</li> </ul>"},{"location":"setup/database-table-setup/#todo","title":"TODO","text":"<p>Setup a json or a csv (to be read by pandas) with some sample data to test and load into the database for testing once configured .</p>"},{"location":"setup/env-config/","title":"Setting up the <code>.env</code> file","text":"<p>Create a <code>.env</code> file in the root directory with the following variables: <pre><code>OPENAI_API_KEY=your_openai_api_key\nLOCAL_DB_NAME=nanobot\nLOCAL_DB_USER=postgres\nLOCAL_DB_PASSWORD=your_password\nLOCAL_DB_HOST=localhost\nLOCAL_DB_PORT=5432\nLOGFIRE_TOKEN=your_logfire_token\nNEON_URL=your_neon_db_url\nUSE_NEON=False (defaults to using local db)\n</code></pre></p> <ul> <li> <p>If you do not have a Logfire token please see the Logfire-Setup Page</p> </li> <li> <p>If you do not have a Neon URL please see the Neon-Setup Page</p> </li> </ul>"},{"location":"setup/logfire-setup/","title":"Setting up Pydantic Logfire","text":"<p>Logfire by Pydantic is used to record the interaction between the LLM and the application.  Using Logfire one is able to see what is being passed to the model, and what the model is returning.  Additionally you can also see the length of timeeach call takes.  </p> <p>To Use the Nanobot-Dev codebase without modification you will need to configure a Logfire account.  The can be used at no charge for a ridicolous number of calls, (10 million free spans/metrics per month).  </p> <p>Follow these steps:</p> <ol> <li>Go to the main website at https://pydantic.dev/logfire and create an account</li> <li>Log into Logfire</li> <li>Go to the Projects Page and creeate a new project.  </li> <li>Generate a <code>write token</code> and save it for future use</li> <li>Copy the logfire token into your <code>.eve</code> file.  Do not use brackets or quotes or spaces.</li> </ol> <p><pre><code>LOGFIRE_TOKEN=[YOUR_TOKEN_HERE] \n</code></pre> This is what the project page looks like. </p> <p></p> <p>In order to see the live updates you will want to click on the <code>Live</code> tab at the top toolbar of the page.  Each time you make an LLM Call from your application, it will update here in the live view.  You can also search all history going up to 30 days back.</p> <p>A call in the live view looks like the following image.</p> <p></p>"},{"location":"setup/neon-setup/","title":"Configuring Neon (Neon.tech)","text":""},{"location":"setup/neon-setup/#account","title":"Account","text":"<p>You will need to set up an account.  There is a free tier which will be fine to get you started. You will need to verify the email address that you are using.  </p>"},{"location":"setup/neon-setup/#project","title":"Project","text":"<p>After verifying your email information, you will need to create a project.  </p> <ul> <li>Below is a screenshot where I have created a nanobot-dev project.</li> <li>You will pick a location that is near the area that this data will serve.    </li> </ul> <p></p>"},{"location":"setup/neon-setup/#database","title":"Database","text":"<p>You will see that your default database name is neondb.  This is fine to keep for now.  </p>"},{"location":"setup/neon-setup/#branches","title":"Branches","text":"<p>Both production and development braches are made.  Note that the development branch is a child of the main production branch.  The Default branch is the <code>production</code> branch.  </p>"},{"location":"setup/neon-setup/#connecting-to-the-database-url","title":"Connecting to the database (URL)","text":"<p>Clicking on the production branch will bring up the following screen</p> <p></p> <p>You then want to click onn the <code>Connect</code> button on the far right which will open a screen that looks like the one below:</p> <p></p> <p>Copy the connection string.  This is the <code>NEON_URL</code> that you will need in your <code>.env</code> file to connect to the database</p>"},{"location":"setup/postgres-local-setup/","title":"Local PosgreSQL Setup","text":"<p>This is a total work under construction -- </p> <p>Maybe should just refer people to setup pages for their particular OS:</p> <ul> <li>Mac-OS</li> <li>LInux</li> <li>WIndows</li> <li>WSL (Windows subsystem on linux)</li> </ul> <p>In theory, if they want to serve this as an application, they should either deploy through a Docker VM or Neon, or similar cloud instance...</p>"},{"location":"setup/running-nanobot/","title":"Running the Nanobot Streamlit Application","text":"<p>from the root directory: <pre><code>streamlit run nanobot.py\n</code></pre></p>"},{"location":"user-guide/00-index-user-guide/","title":"Nanobot Overview","text":""},{"location":"user-guide/00-index-user-guide/#architecture","title":"Architecture","text":"<p>Nanobot is a RAG (Retrieval-Augmented Generation) system with a layered architecture:</p> <ol> <li>Presentation Layer: Streamlit UI (<code>nanobot.py</code>)</li> <li>Service Layer: Core business logic (<code>app/services/</code>)</li> <li>Data Access Layer: Database interactions (<code>app/database/</code>)</li> <li>Utility Layer: Helper functions (<code>app/utils/</code>)</li> </ol>"},{"location":"user-guide/00-index-user-guide/#document-processing-pipeline","title":"Document Processing Pipeline","text":"<p>Documents flow through the system in these stages:</p> <ol> <li>Document conversion (Docling)</li> <li>Text chunking with configurable strategies</li> <li>Embedding generation (OpenAI)</li> <li>Vector storage (PostgreSQL with pgvector)</li> <li>Similarity-based retrieval</li> <li>LLM integration for response generation</li> </ol>"},{"location":"user-guide/00-index-user-guide/#key-features","title":"Key Features","text":"<ul> <li>Modular codebase with clean separation of concerns</li> <li>Multiple document chunking strategies</li> <li>Vector similarity search</li> <li>Interactive Streamlit interface</li> <li>Enterprise-ready database with transaction support</li> <li>Extensible framework for AI integrations</li> </ul>"},{"location":"user-guide/00-index-user-guide/#core-components","title":"Core Components:","text":"<ol> <li>app/ - Main application code</li> <li>services/ - Service layer with document processing, chunking, and API integrations<ul> <li><code>document_service.py</code> - Complete pipeline for document processing</li> <li><code>chunking_service.py</code> - Document chunking strategies</li> <li><code>openai_service.py</code> - OpenAI API integration</li> <li><code>prompt_loader.py</code> - For loading prompt templates</li> </ul> </li> <li>database/ - Database interactions<ul> <li><code>setup.py</code> - Database initialization</li> <li><code>common.py</code> - Shared database utilities</li> <li><code>insert.py</code> - Database insertion operations</li> <li><code>retrieval.py</code> - Vector search and retrieval</li> <li><code>transaction.py</code> - Transaction management</li> <li><code>maintenance.py</code> - Database maintenance tasks</li> </ul> </li> <li>models/ - Data models and validators</li> <li>utils/ - Utility functions<ul> <li>File handling, tokenization, logging, etc.</li> </ul> </li> <li>config/ - Configuration settings</li> <li> <p>prompts/ - Prompt templates</p> </li> <li> <p>Main Scripts:</p> </li> <li><code>nanobot_poc.py</code> - Main Streamlit application with UI</li> <li><code>process_and_load.py</code> - CLI tool for processing documents</li> </ol>"},{"location":"user-guide/00-index-user-guide/#supporting-directories","title":"Supporting Directories:","text":"<ul> <li>data/ - Document storage</li> <li>tests/ - Comprehensive test suite</li> <li>examples/ - Example code </li> <li>sandbox/ - For experimentation and notebooks</li> <li>logs/ - Log files</li> </ul>"},{"location":"user-guide/document-processing/","title":"Document Processing","text":"<p>This guide explains how NanoBot processes documents, from initial conversion to chunking and embedding.</p>"},{"location":"user-guide/document-processing/#supported-document-types","title":"Supported Document Types","text":"<p>NanoBot supports various document types through its document conversion pipeline:</p> <ul> <li>PDF (.pdf): Full support for text extraction, including tables and basic formatting</li> <li>Microsoft Word (.docx): Support for text, tables, and document structure</li> <li>Text files (.txt): Plain text processing</li> <li>Web Pages (URLs): Extract content directly from web pages</li> </ul>"},{"location":"user-guide/document-processing/#document-processing-pipeline","title":"Document Processing Pipeline","text":"<p>The document processing pipeline consists of three main stages:</p> <ol> <li>Document Conversion: Converting documents to a structured format</li> <li>Chunking: Breaking documents into manageable pieces</li> <li>Embedding: Generating vector representations for each chunk</li> </ol>"},{"location":"user-guide/document-processing/#document-conversion","title":"Document Conversion","text":"<p>The first step in processing a document is converting it to a structured format that preserves the document's content and structure. This is handled by the <code>DocumentService</code> class using the Docling library.</p> <pre><code>from app.services.document_service import DocumentService\n\n# Initialize the service\ndocument_service = DocumentService()\n\n# Convert a document\nconverted_doc = document_service.convert_document(\"path/to/document.pdf\")\n</code></pre> <p>During conversion, NanoBot: - Extracts text content - Preserves document structure (headings, paragraphs) - Identifies metadata (title, author, etc.) - Optionally saves intermediate formats for debugging</p>"},{"location":"user-guide/document-processing/#chunking-strategies","title":"Chunking Strategies","text":"<p>After conversion, documents are split into chunks using one of several chunking strategies. Each strategy is optimized for different use cases:</p> Strategy Description Best For default Standard chunking with moderate chunk size General purpose use balanced Balanced approach between context preservation and chunk size Most document types fine_grained Smaller chunks for more precise retrieval Technical documents, reference materials context Larger chunks that preserve more context Q&amp;A, summarization tasks hierarchical Chunks based on document's natural hierarchy Structured documents with clear sections <p>The chunking process is handled by the <code>ChunkingService</code> class:</p> <pre><code>from app.services.chunking_service import ChunkingService\n\n# Initialize the service\nchunking_service = ChunkingService()\n\n# Get information about available strategies\nstrategies = chunking_service.get_available_strategies()\n\n# Chunk a document using a specific strategy\nchunks = chunking_service.chunk_document(document, strategy=\"balanced\")\n\n# Process chunks to extract metadata\nprocessed_chunks = chunking_service.process_chunks(chunks, chunking_strategy=\"balanced\")\n</code></pre>"},{"location":"user-guide/document-processing/#embedding-generation","title":"Embedding Generation","text":"<p>The final step is generating vector embeddings for each chunk using OpenAI's embedding models. These embeddings capture the semantic meaning of the text, enabling similarity search.</p> <pre><code># Generate embeddings for chunks\nchunks_with_embeddings = document_service.get_embeddings_for_chunks(processed_chunks)\n</code></pre> <p>NanoBot uses OpenAI's text embedding models to generate high-dimensional vector representations of each chunk.</p>"},{"location":"user-guide/document-processing/#complete-processing-example","title":"Complete Processing Example","text":"<p>Here's a complete example of processing a document from start to finish:</p> <pre><code>from app.database.transaction import transaction\nfrom app.services.document_service import DocumentService\n\n# Initialize the service\ndocument_service = DocumentService()\n\n# Process a document with the complete pipeline\nwith transaction() as conn:\n    chunks_with_embeddings = document_service.process_document(\n        doc_path=\"path/to/document.pdf\",\n        chunking_strategy=\"balanced\",\n        save_intermediate=True\n    )\n\n    # Now you can insert these chunks into the database\n    # (See the database documentation for details)\n</code></pre>"},{"location":"user-guide/document-processing/#using-the-streamlit-interface","title":"Using the Streamlit Interface","text":"<p>For a more user-friendly experience, you can use the Streamlit interface to process documents:</p> <ol> <li> <p>Start the Streamlit app:    <pre><code>streamlit run nanobot_poc.py\n</code></pre></p> </li> <li> <p>Navigate to the \"Upload\" section</p> </li> <li>Upload your document</li> <li>Select a chunking strategy from the dropdown</li> <li>Click \"Process Document\"</li> </ol> <p>The interface will show progress as the document is processed and provide feedback on the number of chunks created.</p>"},{"location":"user-guide/document-processing/#best-practices","title":"Best Practices","text":"<ul> <li>Choose the right chunking strategy for your document type and use case</li> <li>Process similar documents with the same strategy for consistent results</li> <li>Use meaningful filenames to help with filtering during retrieval</li> <li>Consider document structure when choosing a chunking strategy</li> <li>Monitor token usage when processing large documents</li> </ul>"},{"location":"user-guide/git/","title":"Git Collaboration","text":"<p>This is the first time I will be working with other in the same codebase, and thinking about how this actually will work.  This document is a space for us to update how this works best for us.  </p>"},{"location":"user-guide/git/#branches","title":"Branches","text":"<p>Currently cleaning up <code>clean-main</code> but will probably rename as <code>development</code></p>"},{"location":"user-guide/git/#how-to-work-on-your-own-version-of-the-code","title":"How to work on your own version of the code","text":"<p>There are various options  * create your own personal branch -- create a pull request in the development branch when your feature is tested * create a seperate directory called <code>/sandbox</code>.  Make certain your <code>.gitignore</code> file contains this folder so that it is not committed back to the repo before you are ready.  </p>"},{"location":"user-guide/git/#collaboration-guidelines","title":"\ud83e\udd1d Collaboration Guidelines","text":"<p>DISCLAIMER Below was written by ChatGPT.  I did ask it to be friendly and warm! :-D  </p>"},{"location":"user-guide/git/#working-together","title":"Working Together","text":"<p>To help us keep the project organized and high-quality, we follow a few lightweight practices:</p> <ul> <li>The <code>main</code> branch is protected to ensure stable and reliable code.</li> <li>Changes should come through Pull Requests (PRs) \u2014 it's the best way to review and improve together.</li> <li>Direct pushes to <code>main</code> are restricted to keep history clean and traceable.</li> </ul>"},{"location":"user-guide/git/#opening-pull-requests","title":"Opening Pull Requests","text":"<p>When opening a PR:</p> <ul> <li>Start from a feature branch.</li> <li>One peer approval is encouraged before merging.</li> <li>Please resolve any open review comments or conversations.</li> <li>If new commits are added after approval, a quick re-approval helps keep reviews up to date.</li> <li>Keep your branch in sync with <code>main</code> to avoid conflicts.</li> </ul>"},{"location":"user-guide/git/#merging-options","title":"Merging Options","text":"<p>You are free to choose the merge method that fits best:</p> <ul> <li>Merge, Squash, or Rebase are all supported.</li> <li>Squash merging is recommended for small or self-contained changes to keep commit history tidy.</li> </ul>"},{"location":"user-guide/git/#stewardship","title":"Stewardship","text":"<ul> <li>Admins help guide the project and can bypass branch protections if necessary.</li> <li>Day-to-day contributions, reviews, and merges are open and collaborative.</li> </ul>"},{"location":"user-guide/git/#best-practices","title":"\ud83e\uddf9 Best Practices","text":"<ul> <li>Name branches clearly (e.g., <code>feature/login-page</code>, <code>fix/readme-typo</code>).</li> <li>Try to keep PRs focused on a single topic or improvement.</li> <li>Include a short description in your PR:</li> <li>What was changed</li> <li>Why it was needed</li> <li>How it was tested</li> </ul>"},{"location":"user-guide/git/#quick-pull-request-template-optional","title":"\u2705 Quick Pull Request Template (Optional)","text":"<p>When opening a Pull Request, feel free to use:</p> <pre><code>## Summary\n- [What does this change do?]\n\n## Testing\n- [How was this verified?]\n\n## Review\n- [Anything specific you'd like reviewers to focus on?]\n</code></pre>"},{"location":"user-guide/git/#thank-you-for-contributing-and-helping-the-project-grow","title":"\ud83d\ude80 Thank you for contributing and helping the project grow!","text":""},{"location":"user-guide/tests/","title":"Tests","text":"<p>Last updated 4/26/2025 by sam-i-am</p> <p>The importance of writing test code on an ongoing basis is becomming apparant to me.  This is especially so with the involvement of multiple contributors.  </p> <p>Obviously this test folder should only exist in the development code (as opposed to the deployed production code)</p>"},{"location":"user-guide/tests/#pytest","title":"Pytest","text":"<p>Currently we are using the <code>pytest</code> module for our tests.  As of the date of the writing of this post the test directory contains the following tests:</p> <pre><code>\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 test_database_retrieval.py\n\u2502   \u251c\u2500\u2500 test_config_settings.py\n\u2502   \u251c\u2500\u2500 test_transaction.py\n\u2502   \u251c\u2500\u2500 test_chunking_service.py\n\u2502   \u251c\u2500\u2500 test_error_handling.py\n\u2502   \u251c\u2500\u2500 test_document_service.py\n\u2502   \u251c\u2500\u2500 test_pydantic_validator.py\n\u2502   \u251c\u2500\u2500 __init__.py\n</code></pre> <p>This entire test code can be run from the root directory by running</p> <pre><code>pytest tests\n</code></pre> <p>To be rigerously honest, I asked Claude to generate most of these tests, though I have modified some of them.  But the idea is for every module that we write we should have some tests that continuously test the functionality of the module, and run this test code frequently, at least daily.  </p> <p>This will let us catch quickly where our code may have inadvertly gotten broken or had undesired effects and allow us to fix things quickly.  </p>"},{"location":"user-guide/utils/","title":"Utils (Utility function) Folder","text":"<p>April 24, 2025</p> <p>In <code>app/utils</code> directory there are several modules which handle some housekeeping tasks.  We describe these below</p>"},{"location":"user-guide/utils/#treepy","title":"<code>tree.py</code>","text":"<p>The <code>tree.py</code> utility draws a tree of the project or directory.  To run this from the root directory command line (from the <code>nanobot-poc</code> directory), entering</p> <pre><code>python -m app.utils.tree/utils\n</code></pre> <p>will print the following structure in the terminal</p> <pre><code>app/\n\u251c\u2500\u2500 utils/\n\u2502   \u251c\u2500\u2500 __init.__.py\n\u2502   \u251c\u2500\u2500 json_formatter.py\n\u2502   \u251c\u2500\u2500 logger.py\n\u2502   \u251c\u2500\u2500 logging_examples.py\n\u2502   \u251c\u2500\u2500 tree.py\n\u2502   \u251c\u2500\u2500 file_handling.py\n\u2502   \u251c\u2500\u2500 tokenizer.py\n</code></pre> <p>To print the entire tree structure you would use:</p> <pre><code>python -m app.utils.tree\n</code></pre> <p>You can also add arguments as follows in the following examples: <pre><code># Show entire tree (excluding default dirs)\npython -m app.utils.tree\n\n# Show specific directory\npython -m app.utils.tree app/services\n\n# Show only 1 level deep\npython -m app.utils.tree . 1\n</code></pre></p>"},{"location":"user-guide/utils/#logging_examplespy","title":"<code>logging_examples.py</code>","text":"<p>This code is essentially a test script to test the logging functionality and configuration and will populate test log files in the following directory </p> <p><pre><code>nanobot-poc/\n\u251c\u2500\u2500 logs/\n</code></pre> It is fun from the terminal when in the root <code>nanobot-poc</code> directory with the following command <pre><code>python -m app.utils.logging_examples\n</code></pre></p> <p>I think eventually we may want to move this to test functionality</p>"},{"location":"user-guide/vector-search/","title":"Vector Search","text":"<p>This guide explains how to use NanoBot's vector search capabilities to find relevant information in your processed documents.</p>"},{"location":"user-guide/vector-search/#understanding-vector-search","title":"Understanding Vector Search","text":"<p>NanoBot uses vector similarity search to find information in your documents. Unlike traditional keyword search, vector search understands the semantic meaning of your query, allowing it to find relevant information even when the exact words don't match.</p>"},{"location":"user-guide/vector-search/#how-it-works","title":"How It Works","text":"<ol> <li>Your query is converted to a vector embedding using the same model used for document chunks</li> <li>The database finds chunks with vectors most similar to your query vector</li> <li>Results are ranked by similarity score (higher is better)</li> <li>Optional filters can narrow down results by document or chunking strategy</li> </ol>"},{"location":"user-guide/vector-search/#basic-search","title":"Basic Search","text":"<p>The simplest way to search is to provide a query text:</p> <pre><code>from app.database.transaction import transaction\nfrom app.database.db_retrieval import search_similar_chunks\n\nwith transaction() as conn:\n    results = search_similar_chunks(\n        conn=conn,\n        query_text=\"What is machine learning?\",\n        limit=5  # Return top 5 results\n    )\n\n    # Display results\n    for result in results:\n        print(f\"Similarity: {result['similarity']:.4f}\")\n        print(f\"Text: {result['text'][:200]}...\")\n        print(\"---\")\n</code></pre>"},{"location":"user-guide/vector-search/#filtered-search","title":"Filtered Search","text":"<p>You can narrow down search results using filters:</p> <pre><code>from app.database.transaction import transaction\nfrom app.database.db_retrieval import search_similar_chunks_with_filters\n\nwith transaction() as conn:\n    results = search_similar_chunks_with_filters(\n        conn=conn,\n        query_text=\"What is machine learning?\",\n        limit=5,\n        chunking_strategy=\"balanced\",  # Filter by chunking strategy\n        filename=\"machine_learning.pdf\"  # Filter by filename\n    )\n</code></pre>"},{"location":"user-guide/vector-search/#available-filters","title":"Available Filters","text":"<ul> <li>chunking_strategy: Filter by the chunking strategy used when processing the document</li> <li>filename: Filter by the source document filename</li> </ul>"},{"location":"user-guide/vector-search/#getting-metadata","title":"Getting Metadata","text":"<p>To help with filtering, you can retrieve available metadata values:</p> <pre><code>from app.database.transaction import transaction\nfrom app.database.db_retrieval import get_chunking_strategies, get_filenames\n\nwith transaction() as conn:\n    # Get available chunking strategies\n    strategies = get_chunking_strategies(conn)\n    print(f\"Available strategies: {strategies}\")\n\n    # Get available filenames\n    filenames = get_filenames(conn)\n    print(f\"Available files: {filenames}\")\n</code></pre>"},{"location":"user-guide/vector-search/#understanding-search-results","title":"Understanding Search Results","text":"<p>Each search result contains:</p> <ul> <li>text: The content of the chunk</li> <li>similarity: A score between 0 and 1 indicating how similar the chunk is to your query (higher is better)</li> <li>metadata: Additional information about the chunk, including:</li> <li>filename: The source document</li> <li>page_numbers: The pages where this chunk appears</li> <li>title: The document title or section heading</li> <li>headings: List of headings associated with this chunk</li> <li>chunking_strategy: The strategy used to create this chunk</li> </ul>"},{"location":"user-guide/vector-search/#using-the-streamlit-interface","title":"Using the Streamlit Interface","text":"<p>The Streamlit interface provides a user-friendly way to search your documents:</p> <ol> <li> <p>Start the Streamlit app:    <pre><code>streamlit run nanobot_poc.py\n</code></pre></p> </li> <li> <p>Enter your query in the search box</p> </li> <li>Use the sidebar to configure search parameters:</li> <li>Number of chunks to retrieve</li> <li>Chunking strategy filter</li> <li>Source document filter</li> <li>Click \"Search\" to execute the query</li> <li>View the results, which include:</li> <li>Chunk text</li> <li>Similarity score</li> <li>Source document and page numbers</li> <li>Other metadata</li> </ol>"},{"location":"user-guide/vector-search/#advanced-usage","title":"Advanced Usage","text":""},{"location":"user-guide/vector-search/#combining-with-openai","title":"Combining with OpenAI","text":"<p>You can use the retrieved chunks as context for OpenAI to generate more comprehensive answers:</p> <pre><code>from app.services.openai_service import get_chat_response\nfrom app.database.transaction import transaction\nfrom app.database.db_retrieval import search_similar_chunks_with_filters\n\nwith transaction() as conn:\n    # Search for relevant chunks\n    chunks = search_similar_chunks_with_filters(\n        conn=conn,\n        query_text=\"What is machine learning?\",\n        limit=5\n    )\n\n    # Use chunks as context for OpenAI\n    response = get_chat_response(\n        prompt=\"What is machine learning?\",\n        context_chunks=chunks\n    )\n\n    print(response)\n</code></pre>"},{"location":"user-guide/vector-search/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Limit: Adjust the <code>limit</code> parameter based on your needs. Higher values return more results but may include less relevant chunks.</li> <li>Filters: Use filters to narrow down results when you know which documents or chunking strategies are most relevant.</li> <li>Query Formulation: Be specific in your queries for better results. Vector search works best with clear, focused questions.</li> </ul>"},{"location":"user-guide/vector-search/#best-practices","title":"Best Practices","text":"<ul> <li>Start broad, then narrow: Begin with unfiltered searches, then add filters if needed</li> <li>Experiment with chunking strategies: Different strategies work better for different types of queries</li> <li>Use natural language: Phrase queries as you would ask a human</li> <li>Provide context: Longer, more detailed queries often yield better results</li> <li>Review metadata: Check the source document and page numbers to understand where information comes from</li> </ul>"}]}